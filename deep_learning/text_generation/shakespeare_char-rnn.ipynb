{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.autograd import Variable\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RNN(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, output_size, n_layers=1):\n",
    "        super(RNN, self).__init__()\n",
    "        self.input_size = input_size\n",
    "        self.hidden_size = hidden_size\n",
    "        self.output_size = output_size\n",
    "        self.n_layers = n_layers\n",
    "        \n",
    "        self.encoder = nn.Embedding(input_size, hidden_size)\n",
    "        self.gru = nn.GRU(hidden_size, hidden_size, n_layers)\n",
    "        self.decoder = nn.Linear(hidden_size, output_size)\n",
    "    \n",
    "    def forward(self, input, hidden):\n",
    "        input = self.encoder(input.view(1, -1))\n",
    "        output, hidden = self.gru(input.view(1, 1, -1), hidden)\n",
    "        output = self.decoder(output.view(1, -1))\n",
    "        return output, hidden\n",
    "\n",
    "    def init_hidden(self):\n",
    "        return Variable(torch.zeros(self.n_layers, 1, self.hidden_size))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import unidecode\n",
    "import string\n",
    "import random\n",
    "import time\n",
    "import math\n",
    "import torch\n",
    "from torch.autograd import Variable\n",
    "\n",
    "all_characters = string.printable\n",
    "n_characters = len(all_characters)\n",
    "\n",
    "def read_file(filename):\n",
    "    \"\"\"Read file\"\"\"\n",
    "    f = unidecode.unidecode(open(filename).read())\n",
    "    return f, len(f)\n",
    "\n",
    "def char_tensor(string):\n",
    "    \"\"\"String to tensor\"\"\"\n",
    "    tensor = torch.zeros(len(string)).long()\n",
    "    for c in range(len(string)):\n",
    "        tensor[c] = all_characters.index(string[c])\n",
    "    return Variable(tensor)\n",
    "\n",
    "def elapsed(start):\n",
    "    \"\"\"Get elapsed time\"\"\"\n",
    "    secs = time.time() - start\n",
    "    mins = math.floor(secs / 60)\n",
    "    secs -= mins * 60\n",
    "    return '{}m {}s'.format(mins, secs)\n",
    "\n",
    "def random_chunk(size):\n",
    "    start_index = random.randint(0, file_len - size)\n",
    "    end_index = start_index + size + 1\n",
    "    return file[start_index:end_index]\n",
    "\n",
    "def random_training_set(size=200, verbose=False):    \n",
    "    chunk = random_chunk(size)\n",
    "    if verbose:\n",
    "        print(chunk)\n",
    "    inp = char_tensor(chunk[:-1])\n",
    "    target = char_tensor(chunk[1:])\n",
    "    return inp, target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = os.path.abspath('_data/tiny-shakespeare.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "file_len = 1115394\n",
      "First Citizen:\n",
      "Before we proceed any further, hear me speak.\n",
      "\n",
      "All:\n",
      "Speak, speak.\n",
      "\n",
      "First Citizen:\n",
      "You\n"
     ]
    }
   ],
   "source": [
    "file, file_len = read_file(data_path)\n",
    "print('file_len =', file_len)\n",
    "print(file[:100])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"forbid!\\n\\nGREEN:\\nAh, madam, 'tis too true: and that is worse,\\nThe Lord Northumberland, his son young Henry Percy,\\nThe Lords of Ross, Beaumond, and Willoughby,\\nWith all their powerful friends, are fled t\""
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random_chunk(200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([ 15,  34,  94,  29,  17,  14,  14,  73,  96,  36,  23,  13,\n",
       "          94,  29,  24,  94,  22,  34,  94,  11,  27,  24,  29,  17,\n",
       "          14,  27,  94,  29,  30,  27,  23,  94,  22,  34,  94,  11,\n",
       "          21,  30,  28,  17,  18,  23,  16,  94,  12,  17,  14,  14,\n",
       "          20,  28]),\n",
       " tensor([ 34,  94,  29,  17,  14,  14,  73,  96,  36,  23,  13,  94,\n",
       "          29,  24,  94,  22,  34,  94,  11,  27,  24,  29,  17,  14,\n",
       "          27,  94,  29,  30,  27,  23,  94,  22,  34,  94,  11,  21,\n",
       "          30,  28,  17,  18,  23,  16,  94,  12,  17,  14,  14,  20,\n",
       "          28,  75]))"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random_training_set(50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(prime_str='A', predict_len=100, temperature=0.8):\n",
    "    hidden = decoder.init_hidden()\n",
    "    prime_input = char_tensor(prime_str)\n",
    "    predicted = prime_str\n",
    "\n",
    "    # Use priming string to \"build up\" hidden state\n",
    "    for p in range(len(prime_str) - 1):\n",
    "        _, hidden = decoder(prime_input[p], hidden)\n",
    "    inp = prime_input[-1]\n",
    "    \n",
    "    for p in range(predict_len):\n",
    "        output, hidden = decoder(inp, hidden)\n",
    "        \n",
    "        # Sample from the network as a multinomial distribution\n",
    "        output_dist = output.data.view(-1).div(temperature).exp()\n",
    "        top_i = torch.multinomial(output_dist, 1)[0]\n",
    "        \n",
    "        # Add predicted character to string and use as next input\n",
    "        predicted_char = all_characters[top_i]\n",
    "        predicted += predicted_char\n",
    "        inp = char_tensor(predicted_char)\n",
    "\n",
    "    return predicted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(inp, target):\n",
    "    hidden = decoder.init_hidden()\n",
    "    decoder_optimizer.zero_grad()\n",
    "    loss = 0\n",
    "\n",
    "    for c in range(chunk_len):\n",
    "        output, hidden = decoder(inp[c], hidden)\n",
    "        loss += criterion(output, target[c].unsqueeze(0))\n",
    "\n",
    "    loss.backward()\n",
    "    decoder_optimizer.step()\n",
    "\n",
    "    return loss.data.item() / chunk_len"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0m 58.46490812301636s (100 5%) 2.2629]\n",
      "Whnarlse\n",
      "Rond he my gare, with blotus I love, nod I hat und in hat bome here be the nond and dae\n",
      "I you \n",
      "\n",
      "[1m 57.362316846847534s (200 10%) 2.1968]\n",
      "Whe,\n",
      "Felp to me deace here your be here with ar wither of this vere free\n",
      "Meee sord weet.\n",
      "\n",
      "LOLINE:\n",
      "Musu \n",
      "\n",
      "[2m 54.273353099823s (300 15%) 2.2783]\n",
      "Where mity not sough,\n",
      "To desto will\n",
      "Fuect, beat, I nost we stand sues to and was may well to do of wel \n",
      "\n",
      "[3m 52.438225507736206s (400 20%) 2.0721]\n",
      "Why.\n",
      "\n",
      "She there freeare my no she full such of for ale word unture:\n",
      "No say king, a\n",
      "youming bacce me be \n",
      "\n",
      "[4m 51.30783677101135s (500 25%) 1.9114]\n",
      "Whengoe, buck, affe all-ame to thew forator\n",
      "The for man there afes and the aw ford the hore the dostil \n",
      "\n",
      "[5m 48.33639121055603s (600 30%) 1.8874]\n",
      "When?\n",
      "\n",
      "POMEO:\n",
      "All and this for a geard her thing.\n",
      "\n",
      "GRUMEO:\n",
      "Nom marright your you seets a greather hand \n",
      "\n",
      "[6m 47.84331774711609s (700 35%) 1.9430]\n",
      "Whimes pethere a the good?\n",
      "have brwes over wruhing mink leave act are not they\n",
      "That mince with theaph  \n",
      "\n",
      "[8m 0.3760261535644531s (800 40%) 1.7921]\n",
      "Whe good the mouce\n",
      "Thour nobless give she ham that he noble?\n",
      "\n",
      "LADY ANNE:\n",
      "The he the with word; my we h \n",
      "\n",
      "[9m 9.7022225856781s (900 45%) 2.2442]\n",
      "Wher lead our therefore are\n",
      "Tnown seefrow:\n",
      "And Gongws serving a seper ablate\n",
      "And messs save be shall a \n",
      "\n",
      "[10m 22.08041548728943s (1000 50%) 1.8756]\n",
      "What sir;\n",
      "As and beecter bestick the conferars, a son heallow that she\n",
      "I ave comble not fight deasure, \n",
      "\n",
      "[11m 25.798956394195557s (1100 55%) 2.0589]\n",
      "Which is\n",
      "Far will Juld same minne him ald saudes, the king beseent cand;\n",
      "Math and sharch I be so bewn; \n",
      "\n",
      "[12m 29.39637327194214s (1200 60%) 1.8622]\n",
      "Wh?DWb*ke?\n",
      "ANNE:\n",
      "By the eyes merprakeder of stand do\n",
      "nos?\n",
      "\n",
      "AENENTIO:\n",
      "Not ever live.\n",
      "\n",
      "FaR Have yourste, \n",
      "\n",
      "[13m 26.696704626083374s (1300 65%) 1.9267]\n",
      "Whibe bece and his but; where, I hours wish is better after to he ward's to dester thethe his vether,  \n",
      "\n",
      "[14m 27.103947639465332s (1400 70%) 1.7483]\n",
      "Wh, he thou ip that spomes, stapitiss lobt sree. for come and letter,\n",
      "The cheserre sutate so lutter an \n",
      "\n",
      "[15m 27.54562997817993s (1500 75%) 2.0876]\n",
      "Wher for the ruing sour scout, show issed, to foll confess alwice.\n",
      "\n",
      "Tome to good of I res. I bat en:\n",
      "A \n",
      "\n",
      "[16m 30.268877506256104s (1600 80%) 1.9238]\n",
      "What Rome, us it me;\n",
      "As her make, now, in am my from mrade to her kind chall haves up\n",
      "And morest my an \n",
      "\n",
      "[17m 33.3204984664917s (1700 85%) 1.5288]\n",
      "Where, good this his the sir you,\n",
      "So live the sovers to cown.\n",
      "\n",
      "Sef.\n",
      "Alk ver's it and theele that I wat \n",
      "\n",
      "[18m 34.73025465011597s (1800 90%) 1.6047]\n",
      "Where on cidon the kings revenchosed, wo the stand the weak\n",
      "The dersfavey, leyoung think goon your we  \n",
      "\n",
      "[19m 37.935282707214355s (1900 95%) 2.0445]\n",
      "Whereraw on grarveentain, there this drine is of it a impern lee\n",
      "nochereen, where to denry,\n",
      "I doo her  \n",
      "\n",
      "[20m 41.17139458656311s (2000 100%) 1.9610]\n",
      "Where,\n",
      "And cityian, say the heaver, I mone;\n",
      "As shorpor I poinst the ching, the modio, all rough; liffe \n",
      "\n"
     ]
    }
   ],
   "source": [
    "args = {\n",
    "    \"hidden_size\": 50,\n",
    "    \"n_layers\": 2,\n",
    "    \"lr\": 0.005,\n",
    "    \"n_epochs\": 2000,\n",
    "    \"print_every\": 100,\n",
    "    \"plot_every\": 10,\n",
    "    \"hidden_size\": 300,\n",
    "    \"chunk_len\": 200,\n",
    "}\n",
    "\n",
    "n_epochs = args[\"n_epochs\"]\n",
    "chunk_len = args[\"chunk_len\"]\n",
    "\n",
    "decoder = RNN(n_characters, args[\"hidden_size\"], n_characters, args[\"n_layers\"])\n",
    "decoder_optimizer = torch.optim.Adam(decoder.parameters(), lr=args[\"lr\"])\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "start = time.time()\n",
    "all_losses = []\n",
    "loss_avg = 0\n",
    "\n",
    "for epoch in range(1, n_epochs + 1):\n",
    "    loss = train(*random_training_set(chunk_len))\n",
    "    loss_avg += loss\n",
    "\n",
    "    if epoch % args[\"print_every\"] == 0:\n",
    "        print('[%s (%d %d%%) %.4f]' % (elapsed(start), epoch, epoch / n_epochs * 100, loss))\n",
    "        print(evaluate('Wh', 100), '\\n')\n",
    "\n",
    "    if epoch % args[\"plot_every\"] == 0:\n",
    "        all_losses.append(loss_avg / args[\"plot_every\"])\n",
    "        loss_avg = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
